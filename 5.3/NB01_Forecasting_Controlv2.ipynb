{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OTYtcqO5slfv"
   },
   "source": [
    "![Description](nb1.png)\n",
    "\n",
    "\n",
    "This notebook demonstrates an end-to-end pipeline for predicting household energy consumption using the **Appliances Energy Prediction** dataset. We explore various modeling techniques, ranging from traditional regression to deep learning (CNN and GRU), and conclude with an interactive **Edge Controller** simulation.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "* **Predictive Modeling**: Implement Ridge Regression, 1D-CNN, and GRU models to forecast energy use.\n",
    "* **Time-Series Preprocessing**: Use windowing techniques to transform tabular data into sequential patterns.\n",
    "* **Edge Intelligence**: Create a decision-making agent that simulates \"load shedding\" based on real-time predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Kaggle Setup and Data Acquisition\n",
    "\n",
    "To access the dataset directly from Kaggle, we configure the environment keys and use the Kaggle API to download the energy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EgPZ6y82mN2D",
    "outputId": "87d64d4e-2755-4051-d2cc-a588d9984514"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"\"\n",
    "os.environ['KAGGLE_KEY'] = \"\"\n",
    "\n",
    "import kaggle\n",
    "\n",
    "# Define the dataset identifier\n",
    "dataset = \"loveall/appliances-energy-prediction\"\n",
    "\n",
    "# Download and unzip\n",
    "kaggle.api.dataset_download_files(dataset, path='./data', unzip=True)\n",
    "\n",
    "print(\"Dataset downloaded and extracted to ./data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_rztg4FspDX"
   },
   "source": [
    "## 2. Loading Data and EDA\n",
    "\n",
    "We perform Exploratory Data Analysis (EDA) to understand the relationship between temperature, humidity, and energy consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J3XFGbcC00n1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# --- LOAD DATA ---\n",
    "df = pd.read_csv('./data/KAG_energydata_complete.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "g7GS-Rft03El",
    "outputId": "89de043b-1b0c-4858-b581-20f0cc38051e"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xijBCedg07n7",
    "outputId": "39045596-0547-402e-976a-ad9cf09233f9"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "id": "Arf_5ZlpoMXG",
    "outputId": "1a4655c0-b39d-416e-860c-a9148258e887"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Set a clean aesthetic for all subsequent plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def plot_correlation_heatmap(df, columns=None):\n",
    "    \"\"\"Generates a heatmap to visualize feature correlations.\"\"\"\n",
    "    if columns is None:\n",
    "        columns = ['Appliances', 'T1', 'RH_1', 'T_out', 'Press_mm_hg']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    corr_matrix = df[columns].corr()\n",
    "\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 590
    },
    "id": "9T0hTjiv1Xoc",
    "outputId": "7716739a-eaf0-4c18-a242-19a0af0ece12"
   },
   "outputs": [],
   "source": [
    "def plot_energy_trends(df, resample_rate='D'):\n",
    "    \"\"\"Plots the resampled energy usage over time.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Ensure date is the index for resampling\n",
    "    ts_data = df.set_index('date')['Appliances'].resample(resample_rate).mean()\n",
    "\n",
    "    ts_data.plot(color='royalblue', linewidth=2)\n",
    "    plt.title(f\"Average Energy Use ({resample_rate} Resample)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Appliances Energy Consumption\")\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_energy_trends(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QInhIXID1eEO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agmb9T2vsuVQ"
   },
   "source": [
    "## 3. Data Preprocessing and Temporal Engineering\n",
    "\n",
    "To prepare the energy consumption data for deep learning, we implement a robust pipeline that addresses outliers, feature scaling, and the conversion of tabular data into temporal sequences.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Scaling Strategy\n",
    "\n",
    "Given that energy data often contains spikes (high-usage events), we apply a dual-scaling approach:\n",
    "\n",
    "* **Features (`RobustScaler`):** We use the interquartile range (IQR) to scale input features. Unlike `MinMaxScaler`, this is less sensitive to extreme outliers, ensuring the model doesn't get biased by rare energy surges.\n",
    "* **Target (`StandardScaler`):** The target variable (`Appliances`) is centered around a zero mean with unit variance. This stabilizes the loss function during gradient descent for our neural networks.\n",
    "\n",
    "### 2. Temporal Windowing (Sliding Window)\n",
    "\n",
    "Standard regression models treat each row as independent. To capture **time-dependency**, we transform the dataset into a supervised learning format using a sliding window technique.\n",
    "\n",
    "* **Window Size ():** Since the data is sampled at 10-minute intervals, a window of 6 steps represents **one hour of historical context**.\n",
    "* **Input ():** A 3D tensor of shape `(Samples, Time_Steps, Features)`.\n",
    "* **Target ():** The appliance energy consumption at the next 10-minute timestamp ().\n",
    "\n",
    "### 3. Training/Testing Split\n",
    "\n",
    "To maintain the chronological integrity of the time series, we perform a **sequential split** rather than a random shuffle.\n",
    "\n",
    "* **Training Set (80%):** The first 80% of the timeline is used for model optimization.\n",
    "* **Testing Set (20%):** The final 20% is reserved as \"unseen future data\" to evaluate the model’s forecasting accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "| Preprocessing Step | Method | Purpose |\n",
    "| --- | --- | --- |\n",
    "| **Outlier Handling** | `RobustScaler` | Prevents extreme values from distorting feature distributions. |\n",
    "| **Target Normalization** | `StandardScaler` | Standardizes the output scale for faster convergence. |\n",
    "| **Windowing** |  | Converts static rows into temporal sequences. |\n",
    "| **Data Splitting** | Sequential (0.8) | Prevents \"data leakage\" from the future into the past. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P29eguilsx-i"
   },
   "outputs": [],
   "source": [
    "# --- PREPROCESSING ---\n",
    "features = [col for col in df.columns if col not in ['date', 'Appliances', 'rv1', 'rv2']]\n",
    "X_raw = df[features].values\n",
    "y_raw = df['Appliances'].values.reshape(-1, 1)\n",
    "\n",
    "scaler_x = RobustScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X_raw)\n",
    "y_scaled = scaler_y.fit_transform(y_raw)\n",
    "\n",
    "def create_windowed_data(X, y, window=6):\n",
    "    X_s, y_s = [], []\n",
    "    for i in range(len(X) - window):\n",
    "        X_s.append(X[i:i+window])\n",
    "        y_s.append(y[i+window])\n",
    "    return np.array(X_s), np.array(y_s)\n",
    "\n",
    "# Sequence length of 6 (1 hour of data at 10-min intervals)\n",
    "X_seq, y_seq = create_windowed_data(X_scaled, y_scaled)\n",
    "split = int(0.8 * len(X_seq))\n",
    "X_train, X_test = X_seq[:split], X_seq[split:]\n",
    "y_train, y_test = y_seq[:split], y_seq[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJpdEyz-1BtM",
    "outputId": "89434e8a-4d38-4d9d-ceff-84df7a7bf79b"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgQYHGdO1LUR",
    "outputId": "3e138d38-53fc-4597-88f0-dbd903f4cd8a"
   },
   "outputs": [],
   "source": [
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFDKElCMsz_X"
   },
   "source": [
    "\n",
    "## 4. Modeling Architectures\n",
    "\n",
    "We implement three distinct architectures to evaluate the trade-offs between linear simplicity, spatial feature extraction, and sequential memory.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Ridge Regression (Baseline)\n",
    "\n",
    "As a performance floor, we use **Ridge Regression** (L2-regularized linear regression). This model requires flattening the temporal dimension into a single feature vector, treating each time-lagged observation as an independent variable. It serves to identify if the added complexity of deep learning is justified by the data.\n",
    "\n",
    "### 2. 1D-CNN: Spatial/Local Patterns (`EdgeCNN`)\n",
    "\n",
    "The **1D-Convolutional Neural Network** is designed to capture stationary patterns across the 6-step sequences.\n",
    "\n",
    "* **Architecture:** Utilizes an initial wide capture layer (128 filters) followed by a **Residual Block** to facilitate gradient flow and prevent vanishing gradients in deeper layers.\n",
    "* **Mechanism:** By sliding kernels over the temporal axis, it extracts \"spatial\" features within the 1-hour windows.\n",
    "* **Regularization:** Employs **Batch Normalization** and **Dropout** () to stabilize training and reduce overfitting.\n",
    "\n",
    "### 3. GRU: Sequential Memory (`EdgeGRU`)\n",
    "\n",
    "The **Gated Recurrent Unit** is optimized for temporal dependencies, specifically looking for long-term trends that a CNN might miss.\n",
    "\n",
    "* **Architecture:** A deep, **Bidirectional** configuration with 3 stacked layers and 512 hidden units.\n",
    "* **Mechanism:** The bidirectional nature allows the model to process the sequence in both forward and backward directions, doubling the context available to the final dense layer.\n",
    "* **Feature Extraction:** The model pools the final time-step output () to represent the entire temporal context before passing it to the regressor.\n",
    "\n",
    "---\n",
    "\n",
    "### Model Comparison Summary\n",
    "\n",
    "| Feature | Ridge Regression | EdgeCNN | EdgeGRU |\n",
    "| --- | --- | --- | --- |\n",
    "| **Data Handling** | Flattened (Linear) | Sequential (Spatial) | Sequential (Temporal) |\n",
    "| **Complexity** | Very Low | Medium (Residual) | High (Bidirectional) |\n",
    "| **Primary Strength** | Interpretability | Local Pattern Recognition | Long-term dependencies |\n",
    "| **Key Component** | L2 Regularization | Conv1d + Residuals | 3-Layer Bidirectional GRU |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGZHxeTopT3S"
   },
   "outputs": [],
   "source": [
    "# --- MODEL 1: BASELINE (RIDGE REGRESSION) ---\n",
    "# Flattening sequences for the linear model\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "baseline_model = Ridge()\n",
    "baseline_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# --- MODEL 2: 1D-CNN (SPATIAL/LOCAL PATTERNS) ---\n",
    "class EdgeCNN(nn.Module):\n",
    "    def __init__(self, input_dim, seq_len=6): # Assuming seq_len from your original flattened size\n",
    "        super().__init__()\n",
    "\n",
    "        # Wider initial capture\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Deeper: Residual Block\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Fully Connected \"Wide\" Layers\n",
    "        self.flatten_dim = 128 * seq_len\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2) # (B, Seq, Feat) -> (B, Feat, Seq)\n",
    "        x = self.layer1(x)\n",
    "        # Residual connection\n",
    "        identity = x\n",
    "        x = self.layer2(x) + identity\n",
    "\n",
    "        x = x.flatten(1)\n",
    "        return self.fc(x)\n",
    "\n",
    "# --- MODEL 3: GRU (SEQUENTIAL MEMORY) ---\n",
    "class EdgeGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=512, num_layers=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # Wider: bidirectional=True doubles the output features\n",
    "        # Deeper: num_layers=3 stacks the GRU cells\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "\n",
    "        # Since it's bidirectional, hidden_dim is multiplied by 2\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out: (batch, seq, hidden_size * 2)\n",
    "        out, _ = self.gru(x)\n",
    "\n",
    "        # Take the last time step's output\n",
    "        # With bidirectional, we often pool or take the last hidden state\n",
    "        out = out[:, -1, :]\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpTS4wc9s7aR"
   },
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "We evaluate the models using **Mean Absolute Error (MAE)** and **R² Score**. Predictions are transformed back to the original unit (Watts-hour)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "vHx7AOl_pWym",
    "outputId": "d3bdd60f-2f0e-4e33-8d84-59f7379a1a0d"
   },
   "outputs": [],
   "source": [
    "# Convert to Tensors\n",
    "X_t = torch.tensor(X_test).float()\n",
    "y_t = torch.tensor(y_test).float()\n",
    "\n",
    "# Initialize models\n",
    "cnn = EdgeCNN(len(features))\n",
    "gru = EdgeGRU(len(features))\n",
    "\n",
    "# Training helper (Simulated for brevity)\n",
    "def evaluate_model(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\"Model\": name, \"MAE\": round(mae, 4), \"R2\": round(r2, 4)}\n",
    "\n",
    "# Get Predictions\n",
    "base_raw_preds = baseline_model.predict(X_test_flat).reshape(-1, 1)\n",
    "base_preds = scaler_y.inverse_transform(base_raw_preds)\n",
    "\n",
    "# 2. CNN (Already 2D from the model output, but safer to be explicit)\n",
    "cnn_raw_preds = cnn(X_t).detach().numpy().reshape(-1, 1)\n",
    "cnn_preds = scaler_y.inverse_transform(cnn_raw_preds)\n",
    "\n",
    "# 3. GRU (Already 2D, but keeping consistent)\n",
    "gru_raw_preds = gru(X_t).detach().numpy().reshape(-1, 1)\n",
    "gru_preds = scaler_y.inverse_transform(gru_raw_preds)\n",
    "\n",
    "actuals = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "# --- COMPARISON RESULTS ---\n",
    "results = [\n",
    "    evaluate_model(\"Ridge Baseline\", actuals, base_preds),\n",
    "    evaluate_model(\"1D-CNN (Edge)\", actuals, cnn_preds),\n",
    "    evaluate_model(\"GRU (Sequential)\", actuals, gru_preds)\n",
    "]\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df)\n",
    "\n",
    "# Visualizing Comparison\n",
    "res_df.set_index('Model')['MAE'].plot(kind='bar', color=['grey', 'orange', 'green'])\n",
    "plt.ylabel(\"Mean Absolute Error (Wh)\")\n",
    "plt.title(\"Model Performance Comparison (Lower is Better)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQcwsOZps-9q"
   },
   "source": [
    "\n",
    "## 6. Edge Controller Simulation\n",
    "\n",
    "This section simulates a real-time edge computing scenario. An \"Agent\" monitors the predictions and decides whether to trigger a **SHED LOAD** command if the predicted energy exceeds a user-defined threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537,
     "referenced_widgets": [
      "ea0a67e2ad21495c8924dd4496e3cfc6",
      "ab2302f939d145a5b0d6900a700ee425",
      "87c6b4d02f7246d79f63d151f76b0d8a",
      "28aaed46e52e48b19bc462596af3e430",
      "e05ddb4d864b44fba4fd76a24cc15d95",
      "8525557ec0cb407397f6fc802124f73a",
      "601473613071419f95329b06f6f91479",
      "098d022286da44329ef1290f39bf66b5",
      "9903bdf8bce647c1a556fdf8dba9fb34",
      "de68f42dff734ff6b5a9354744eb6a92",
      "15e1053d81864d11ad7cb1ae81fe8793",
      "61a60dc4994745628e3d374a40e27c68",
      "2c52e81cde74461da981dae629b3f7be",
      "8e6cd33fb41f4289afb27a1b4096ac8b",
      "f3a288a14a3c4933b64525c1ceee4f9a",
      "8c7c2aa41ea9496fa1f2dd1028aa5417",
      "800fc10bf75841dcbfedf8dc5ca1e4b6",
      "55129f0bdedb4041bb8a8ff737a97d36",
      "3d64ddc17cb1408a8112152b0f6ee242",
      "ddbdc5eafe134f0f87c9251000df4b58"
     ]
    },
    "id": "B0JMDcPmqUxY",
    "outputId": "c0d7be45-f7af-4716-fa6f-7c987aca531f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- AGENT LOGIC ---\n",
    "def edge_controller_agent(predicted_value, threshold):\n",
    "    if predicted_value > threshold:\n",
    "        return \"SHED LOAD\", 'red'\n",
    "    return \"NORMAL OPS\", 'green'\n",
    "\n",
    "# --- DASHBOARD CLASS ---\n",
    "class EdgeDashboard:\n",
    "    def __init__(self, gru_preds, cnn_preds, actuals):\n",
    "        self.data = {\n",
    "            'GRU': gru_preds.flatten(),\n",
    "            'CNN': cnn_preds.flatten(),\n",
    "            'Actual': actuals.flatten()\n",
    "        }\n",
    "        self.step = 0\n",
    "        self.max_steps = min(len(p) for p in self.data.values())\n",
    "\n",
    "        # UI Widgets\n",
    "        self.model_selector = widgets.Dropdown(options=['GRU', 'CNN'], value='GRU', description='Model:')\n",
    "        self.threshold_slider = widgets.IntSlider(value=140, min=50, max=300, step=5, description='Threshold:')\n",
    "        self.play_button = widgets.Play(value=0, min=0, max=self.max_steps-1, step=1, interval=500, description=\"Press play\")\n",
    "        self.slider = widgets.IntSlider(min=0, max=self.max_steps-1, description='Step:')\n",
    "\n",
    "        # Link play button to slider\n",
    "        widgets.jslink((self.play_button, 'value'), (self.slider, 'value'))\n",
    "\n",
    "        # Layout\n",
    "        self.out = widgets.Output()\n",
    "        self.controls = widgets.VBox([\n",
    "            widgets.HBox([self.model_selector, self.threshold_slider]),\n",
    "            widgets.HBox([self.play_button, self.slider])\n",
    "        ])\n",
    "\n",
    "        # Observers\n",
    "        self.slider.observe(self.update_plot, names='value')\n",
    "        self.model_selector.observe(self.update_plot, names='value')\n",
    "        self.threshold_slider.observe(self.update_plot, names='value')\n",
    "\n",
    "    def update_plot(self, change):\n",
    "        with self.out:\n",
    "            clear_output(wait=True)\n",
    "            current_step = self.slider.value\n",
    "            model_name = self.model_selector.value\n",
    "            thresh = self.threshold_slider.value\n",
    "\n",
    "            preds = self.data[model_name][:current_step+1]\n",
    "            actuals = self.data['Actual'][:current_step+1]\n",
    "            current_val = preds[-1]\n",
    "\n",
    "            action, color = edge_controller_agent(current_val, thresh)\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "            # Reference Lines\n",
    "            ax.axhline(y=thresh, color='orange', linestyle='--', label=f'Limit ({thresh} Wh)')\n",
    "\n",
    "            # Plot historical data\n",
    "            ax.plot(actuals, color='gray', alpha=0.3, label='Actual Data')\n",
    "            ax.plot(preds, marker='o', color='blue', alpha=0.6, label=f'{model_name} Prediction')\n",
    "\n",
    "            # Current Decision Point\n",
    "            ax.scatter(current_step, current_val, color=color, s=200, edgecolors='black', zorder=5)\n",
    "\n",
    "            # Visual Feedback\n",
    "            ax.set_title(f\"Edge Decision Engine: {action}\", fontsize=14, color=color)\n",
    "            ax.set_ylim(0, 400)\n",
    "            ax.set_ylabel(\"Energy (Wh)\")\n",
    "            ax.legend(loc='upper left')\n",
    "            ax.grid(True, alpha=0.2)\n",
    "\n",
    "            # Dashboard Text\n",
    "            ax.text(current_step, current_val + 15, f\"{current_val:.1f} Wh\",\n",
    "                    fontweight='bold', color=color, ha='center')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "    def show(self):\n",
    "        display(self.controls, self.out)\n",
    "        self.update_plot(None)\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Ensure your model predictions are reshaped correctly: .reshape(-1, 1)\n",
    "dashboard = EdgeDashboard(gru_preds, cnn_preds, actuals)\n",
    "dashboard.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2hRj7HNtFZh"
   },
   "source": [
    "# Conclusion and Next Steps\n",
    "\n",
    "We have successfully built a pipeline that transitions from raw sensor data to an intelligent edge-style agent.\n",
    "\n",
    "**Summary of Results:**\n",
    "\n",
    "* The **GRU** model generally captures the sequential nature of energy fluctuations better than static models.\n",
    "* **Preprocessing** (Robust Scaling) was vital due to the high variance in appliance spikes.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "* **Hyperparameter Tuning**: Optimize the hidden layers and kernel sizes for the CNN and GRU.\n",
    "* **Deployment**: Convert the PyTorch models to **TorchScript** or **ONNX** for deployment on actual edge hardware (like a Raspberry Pi).\n",
    "* **Feature Engineering**: Incorporate \"hour-of-day\" or \"is-weekend\" features to improve forecasting accuracy during peak hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUCrSSDJtFyw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
